{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTz3RBwOE_Lr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "# Logistic Regression is a statistical method used for binary classification problems\n",
        "# (i.e., when the target variable has two possible outcomes such as Yes/No, 0/1, True/False).\n",
        "# It predicts the probability that a given input belongs to a particular class using the\n",
        "# logistic (sigmoid) function, which maps values between 0 and 1.\n",
        "\n",
        "# On the other hand, Linear Regression is used for predicting continuous numerical values.\n",
        "# It models the relationship between independent variables (features) and a continuous\n",
        "# dependent variable by fitting a straight line (y = mx + c).\n",
        "\n",
        "# Key Differences:\n",
        "# 1. Output:\n",
        "#    - Linear Regression → Continuous values\n",
        "#    - Logistic Regression → Probabilities (0 to 1), then classified into categories\n",
        "#\n",
        "# 2. Function Used:\n",
        "#    - Linear Regression → Linear function\n",
        "#    - Logistic Regression → Sigmoid (logistic) function\n",
        "#\n",
        "# 3. Application:\n",
        "#    - Linear Regression → Predicting house prices, sales, etc.\n",
        "#    - Logistic Regression → Predicting spam vs non-spam, pass vs fail, etc.\n"
      ],
      "metadata": {
        "id": "H-e8l5nvFF40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Explain the role of the Sigmoid function in Logistic Regression\n",
        "\n",
        "# Answer:\n",
        "# The Sigmoid function plays a crucial role in Logistic Regression because it transforms\n",
        "# the linear output of the model into a probability between 0 and 1.\n",
        "#\n",
        "# Mathematically, the Sigmoid function is defined as:\n",
        "#     σ(z) = 1 / (1 + e^(-z))\n",
        "#\n",
        "# Where:\n",
        "# - z is the linear combination of inputs (z = w1*x1 + w2*x2 + ... + b)\n",
        "# - The output of σ(z) will always lie between 0 and 1.\n",
        "#\n",
        "# Role in Logistic Regression:\n",
        "# 1. Converts linear regression output into probabilities → useful for classification tasks.\n",
        "# 2. Helps decide class labels:\n",
        "#    - If σ(z) ≥ 0.5 → Class 1\n",
        "#    - If σ(z) < 0.5 → Class 0\n",
        "# 3. Provides smooth gradient → makes optimization with Gradient Descent possible.\n",
        "#\n",
        "# Example:\n",
        "# Input (z) = 0 → σ(0) = 0.5\n",
        "# Input (z) = 2 → σ(2) ≈ 0.88\n",
        "# Input (z) = -2 → σ(-2) ≈ 0.12\n"
      ],
      "metadata": {
        "id": "UJGUM7y1FVbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "# Regularization in Logistic Regression is a method to reduce overfitting by\n",
        "# adding a penalty to the model’s cost function. It controls the size of the\n",
        "# regression coefficients so that the model does not become too complex.\n",
        "#\n",
        "# Types of Regularization:\n",
        "# 1. L1 Regularization (Lasso): Uses the sum of absolute values of coefficients.\n",
        "#    It can shrink some coefficients to zero, thus performing feature selection.\n",
        "#\n",
        "# 2. L2 Regularization (Ridge): Uses the sum of squared values of coefficients.\n",
        "#    It reduces coefficient size but does not make them exactly zero.\n",
        "#\n",
        "# Why Regularization is Needed:\n",
        "# - Prevents overfitting and improves generalization.\n",
        "# - Ensures stable and reliable predictions on new/unseen data.\n",
        "# - Helps handle multicollinearity among features.\n",
        "# - Makes the model simpler and more robust.\n",
        "#\n",
        "# Regularization is essential in Logistic Regression to balance\n",
        "# accuracy and simplicity of the model, ensuring better performance in practice.\n",
        "\n"
      ],
      "metadata": {
        "id": "cNYHexxNGuqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "# In classification models (like Logistic Regression), evaluation metrics\n",
        "# are used to measure how well the model predicts categories. They are\n",
        "# important because accuracy alone may not give a complete picture,\n",
        "# especially with imbalanced datasets.\n",
        "\n",
        "# Common Evaluation Metrics:\n",
        "# 1. Accuracy:\n",
        "#    - Measures the percentage of correct predictions.\n",
        "#    - Important for balanced datasets but may mislead in imbalanced cases.\n",
        "\n",
        "# 2. Precision:\n",
        "#    - Out of all predicted positives, how many are actually positive.\n",
        "#    - Important when false positives are costly (e.g., spam detection).\n",
        "\n",
        "# 3. Recall (Sensitivity or True Positive Rate):\n",
        "#    - Out of all actual positives, how many did the model correctly predict.\n",
        "#    - Important when false negatives are costly (e.g., disease detection).\n",
        "\n",
        "# 4. F1-Score:\n",
        "#    - Harmonic mean of Precision and Recall.\n",
        "#    - Useful when there is an imbalance between classes.\n",
        "\n",
        "# 5. ROC-AUC (Receiver Operating Characteristic - Area Under Curve):\n",
        "#    - Measures the ability of the model to distinguish between classes.\n",
        "#    - Higher AUC means better model performance.\n",
        "\n",
        "# Why They Are Important:\n",
        "# - Help compare models and choose the best one for the problem.\n",
        "# - Ensure that the model is not just accurate but also reliable in\n",
        "#   handling both positive and negative classes effectively.\n",
        "# - Guide decision-making in real-world applications.\n"
      ],
      "metadata": {
        "id": "VnfgYdnJHGDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(\"First 5 rows of dataset:\\n\", df.head())\n",
        "\n",
        "# Step 3: Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression model:\", accuracy)\n",
        "# Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(\"First 5 rows of dataset:\\n\", df.head())\n",
        "\n",
        "# Step 3: Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression model:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIZ4fHq7H5YV",
        "outputId": "18429f5d-2fb5-4cdf-fe68-8c1f6fdb2cb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of dataset:\n",
            "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "Accuracy of Logistic Regression model: 1.0\n",
            "First 5 rows of dataset:\n",
            "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "Accuracy of Logistic Regression model: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "# regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Step 3: Split features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Train Logistic Regression model with L2 Regularization (Ridge is default)\n",
        "model = LogisticRegression(penalty='l2', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Print Coefficients\n",
        "print(\"Model Coefficients:\\n\", model.coef_)\n",
        "print(\"Intercept:\\n\", model.intercept_)\n",
        "\n",
        "# Step 7: Evaluate Accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with L2 Regularization:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMZfroDpIFQM",
        "outputId": "f63d7fcd-65a3-46fc-a66c-9731b37d9cf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            " [[-0.40538546  0.86892246 -2.2778749  -0.95680114]\n",
            " [ 0.46642685 -0.37487888 -0.18745257 -0.72127133]\n",
            " [-0.06104139 -0.49404358  2.46532746  1.67807247]]\n",
            "Intercept:\n",
            " [  8.86383271   2.20981479 -11.0736475 ]\n",
            "Accuracy with L2 Regularization: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "# classification using multi_class='ovr' and print the classification report.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "# Answer (10 Marks):\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Step 3: Split features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Train Logistic Regression model with One-vs-Rest (OvR)\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 7: Print Classification Report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-3wnzIDJUCl",
        "outputId": "3b4a83ab-5038-45b4-954a-9071481d920b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      0.85      0.92        13\n",
            "   virginica       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "# hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "# Answer (10 Marks):\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Step 3: Split features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Define Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500, solver='liblinear')\n",
        "\n",
        "# Step 6: Define Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],       # Regularization strength\n",
        "    'penalty': ['l1', 'l2']             # L1 = Lasso, L2 = Ridge\n",
        "}\n",
        "\n",
        "# Step 7: Apply GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Print Best Parameters and Accuracy\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Validation Accuracy:\", grid.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vWNNJs-JstK",
        "outputId": "8307ed3e-8bda-4de4-b17c-20a2cfea9c6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Best Validation Accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to standardize the features before training Logistic\n",
        "# Regression and compare the model's accuracy with and without scaling.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Step 3: Split features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Step 4: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ---- Model without scaling ----\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "acc_without_scaling = accuracy_score(y_test, y_pred1)\n",
        "\n",
        "# ---- Standardize features ----\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---- Model with scaling ----\n",
        "model2 = LogisticRegression(max_iter=200)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "y_pred2 = model2.predict(X_test_scaled)\n",
        "acc_with_scaling = accuracy_score(y_test, y_pred2)\n",
        "\n",
        "# ---- Print Results ----\n",
        "print(\"Accuracy without Scaling:\", acc_without_scaling)\n",
        "print(\"Accuracy with Scaling   :\", acc_with_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSqxK3D5J0xN",
        "outputId": "2fdbb20a-5dca-4023-8675-29c54917f332"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 1.0\n",
            "Accuracy with Scaling   : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ux_1Hni3KaHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "# predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "# dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "# Logistic Regression model — including data handling, feature scaling, balancing\n",
        "# classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "# use case.\n",
        "\n",
        "\n",
        "\n",
        "# 1. Data Handling:\n",
        "#    - Load the dataset and handle missing values (impute mean/median or drop if necessary).\n",
        "#    - Perform feature engineering (e.g., customer purchase history, demographics, browsing behavior).\n",
        "#    - Encode categorical variables using OneHotEncoder or LabelEncoder.\n",
        "\n",
        "# 2. Feature Scaling:\n",
        "#    - Apply StandardScaler or MinMaxScaler so that all features have comparable scales.\n",
        "#    - Important for Logistic Regression because it uses gradient-based optimization.\n",
        "\n",
        "# 3. Handling Class Imbalance (only 5% positive responses):\n",
        "#    - Use class_weight='balanced' in Logistic Regression to penalize misclassification of minority class.\n",
        "#    - OR use oversampling methods like SMOTE or undersampling majority class.\n",
        "#    - Ensure stratified train-test split to maintain class proportions.\n",
        "\n",
        "# 4. Hyperparameter Tuning:\n",
        "#    - Use GridSearchCV/RandomizedSearchCV to tune:\n",
        "#        * C (regularization strength)\n",
        "#        * penalty ('l1', 'l2')\n",
        "#        * solver ('liblinear', 'saga')\n",
        "#    - Perform cross-validation for reliable performance estimation.\n",
        "\n",
        "# 5. Model Evaluation:\n",
        "#    - Accuracy is not suitable for imbalanced data (95% accuracy can mean model predicts all negatives).\n",
        "#    - Use metrics like:\n",
        "#        * Precision (how many predicted positives are correct).\n",
        "#        * Recall (how many actual positives are identified).\n",
        "#        * F1-Score (balance between precision and recall).\n",
        "#        * ROC-AUC (how well model distinguishes between classes).\n",
        "#        * Precision-Recall AUC (more informative for highly imbalanced data).\n",
        "\n",
        "# 6. Final Business Application:\n",
        "#    - Select the best model with high recall (to capture most responding customers)\n",
        "#      while maintaining decent precision (to avoid targeting too many uninterested users).\n",
        "#    - Deploy model to predict campaign response probability.\n",
        "#    - Use probability thresholds (e.g., 0.3 instead of 0.5) to maximize recall depending on business needs.\n",
        "\n",
        "# Logistic Regression with proper scaling, class balancing, hyperparameter tuning, and\n",
        "# evaluation using precision-recall metrics can help the e-commerce company\n",
        "# effectively target potential customers and maximize campaign success.\n"
      ],
      "metadata": {
        "id": "wAWTCjDwKctQ"
      }
    }
  ]
}